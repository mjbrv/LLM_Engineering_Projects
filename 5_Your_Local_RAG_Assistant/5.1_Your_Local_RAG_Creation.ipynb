{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local RAG Part 1: RAG Pipeline Initialization and Creation\n",
    "\n",
    "- Gattering all text documents in the provided local directory\n",
    "- Processing the files, extacting and embeding the text content\n",
    "- Creating a new vector database and saving the embedings\n",
    "- visualizing the created vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from typing import List\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import chardet  # For detecting file encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for langchain\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_chroma import Chroma\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "OPENAI_MODEL = \"gpt-4o-mini\" #\"gpt-4o\"\n",
    "CLAUDE_MODEL = \"claude-3-5-sonnet-20240620\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "# Want to keep costs ultra-low? Uncomment these lines:\n",
    "# OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "# CLAUDE_MODEL = \"claude-3-haiku-20240307\"\n",
    "\n",
    "db_name = \"mj_vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_documents(directory: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Find all PDF and Word files in the given directory and its subdirectories,\n",
    "    excluding hidden files and directories\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to the directory to search\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of file paths\n",
    "    \"\"\"\n",
    "    document_paths = []\n",
    "    extensions = ('.pdf', '.doc', '.docx')\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Skip hidden directories (in-place modification of dirs)\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        \n",
    "        for file in files:\n",
    "            # Skip hidden files and check for valid extensions\n",
    "            if not file.startswith(('.', '~', '$')) and file.lower().endswith(extensions):\n",
    "                full_path = os.path.join(root, file)\n",
    "                document_paths.append(full_path)\n",
    "                print(f\"Found document: {full_path}\")\n",
    "    \n",
    "    # Sort the paths for consistent ordering\n",
    "    document_paths.sort()\n",
    "    \n",
    "    print(f\"\\nTotal document files found: {len(document_paths)}\")\n",
    "    return document_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(document_paths: List[str]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load documents using appropriate LangChain loaders based on file extension\n",
    "    \n",
    "    Args:\n",
    "        document_paths (List[str]): List of file paths to load\n",
    "        \n",
    "    Returns:\n",
    "        List[Document]: List of LangChain Document objects\n",
    "    \"\"\"\n",
    "    from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "    \n",
    "    documents = []\n",
    "    extensions = {\n",
    "        '.pdf': PyPDFLoader,\n",
    "        '.docx': Docx2txtLoader,\n",
    "        '.doc': Docx2txtLoader  # Note: .doc files might need a different loader\n",
    "    }\n",
    "    \n",
    "    for file_path in document_paths:\n",
    "        file_extension = os.path.splitext(file_path.lower())[1]\n",
    "        if file_extension in extensions:\n",
    "            try:\n",
    "                # Load the document using appropriate loader\n",
    "                loader = extensions[file_extension](file_path)\n",
    "                doc_folder = os.path.basename(os.path.dirname(file_path))\n",
    "                doc_name = file_path.split('/')[-1]\n",
    "                \n",
    "                # Load and process the documents\n",
    "                loaded_docs = loader.load()\n",
    "                \n",
    "                # Add metadata to each document\n",
    "                for doc in loaded_docs:\n",
    "                    doc.metadata.update({\n",
    "                        \"source\": file_path,\n",
    "                        \"doc_folder\": doc_folder,\n",
    "                        \"doc_name\": doc_name,\n",
    "                        \"file_type\": file_extension\n",
    "                    })\n",
    "                    documents.append(doc)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(documents)}\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding documents...\n",
      "Found document: /Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering/SETUP-PC.pdf\n",
      "Found document: /Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering/all_summaries copy.docx\n",
      "Found document: /Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering/reqdoc.docx\n",
      "Found document: /Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering/AISera_2024.pdf\n",
      "Found document: /Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering/SETUP-linux.pdf\n",
      "Found document: /Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering/SETUP-mac.pdf\n",
      "Found document: /Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering/all_summaries.docx\n",
      "Found document: /Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering/mj_rag/files/all_summaries_copy.docx\n",
      "Found document: /Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering/mj_rag/files/lockmart.pdf\n",
      "\n",
      "Total document files found: 9\n",
      "Found 9 document files\n",
      "\n",
      "Total documents loaded: 172\n"
     ]
    }
   ],
   "source": [
    "# Directory to search\n",
    "search_directory =  \"/Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering\"\n",
    "\n",
    "# Find all documents\n",
    "print(\"Finding documents...\")\n",
    "document_paths = find_documents(search_directory)\n",
    "print(f\"Found {len(document_paths)} document files\")\n",
    "\n",
    "# Then load them into LangChain Document objects\n",
    "documents = load_documents(document_paths)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Users/javadmollakazemi/PycharmProjects/15_llm_engineering/llm_engineering/udemy_summarizer/all_summaries copy.docx', 'doc_folder': 'udemy_summarizer', 'doc_name': 'all_summaries copy.docx', 'file_type': '.docx'}, page_content=\"128. Day 1 - Fine-Tuning Large Language Models- From Inference to Training\\n\\nSummary\\n\\nIntroduction\\n\\nThe speaker is moving from the excitement around the topic of inference in earlier weeks to the world of training models. Training models involves going into the specifics of how to enhance their performance at inference. \\n\\nFocus on Data\\n\\nThe speaker indicates that understanding the data is essential. This involves curating the data, cleaning it, and visualizing it to ensure that it is in an optimal state for model training. Achieving project success and how to gauge it is also discussed.\\n\\nReview of Past Weeks\\n\\nThe speaker then reviews the previous weeks:\\n\\nWeek 1: Introduced frontier models.\\n\\nWeek 2: Covered using multiple APIs and building UIs with Gradio and Multi-modality.\\n\\nWeek 3: Explored Hugging Face, Pipelines Tokenizers, and models.\\n\\nWeek 4: Focused on selecting models, using code generation, & optimizing code speed.\\n\\nWeek 5: Revolved around rag (a hot topic).\\n\\nWeek 6: Transitions to fine-tuning a frontier model, moving into the realm of training.\\n\\nTransition from Inference to Training\\n\\nNow the course is moving from inference to training, which involves tweaking the parameters of a deep neural network based on data. The speaker mentions that training a multi-billion parameter Language Model (LM) is expensive and typically requires large budgets. But transfer learning provides the opportunity to take an existing trained LM and further train it with a specific dataset (fine-tuning).\\n\\nIntroduction to a New Problem\\n\\nNext, a commercial problem relating to an e-commerce company is introduced. The aim is to build a model that can estimate the price of a product based on its description. The speaker recognizes that this seems like a regression problem but argues that the approach involves a generative AI solution that generates text. Still, the frontier models turn out to be highly efficient even with this kind of problem.\\n\\nThis problem is said to be a perfect one for working with because it is easier to measure the performance of the model in terms of its accuracy in guessing the price of a product.\\n\\n\\n132. Day 1 - Evaluating LLM Performance- Model-Centric vs Business-Centric Metrics\\n\\nSummary \\n\\nData Scrubbing Feedback and Results\\n\\nThe text starts by emphasizing the importance of data scrubbing, reminding the audience to audit the process for any missed relevant data. The speaker highlights the profound effect of improved data quality on model performance. He comments on the work done in earlier data preprocessing and scrubbing, including a reference to a Jupyter notebook that needs further evaluation. \\n\\nModel Evaluation Metrics\\n\\nNext, the author delves into how model performance will be assessed — both by the data scientists and by the business stakeholders. He distinguishes between model-centric metrics, such as training and validation loss and root mean squared log error (RMSLE), and business-centric metrics. While model-centric metrics help grasp the model's mathematical performance, business-centric metrics reflect the impact of the model on the business goals, resonating with the higher management.\\n\\nModel-Centric Metrics\\n\\nThe speaker talks about two specific common metrics for evaluation. One is RMSLE, a balanced metric that weighs both absolute differences and percentage differences — thus, it won't unfairly penalize the model for minor value discrepancies. The other metric is the mean squared error, but it can be problematic as it exponentially penalizes larger price differences.\\n\\nBusiness-Centric Metrics\\n\\nThe speaker then discusses business-centric metrics, including average absolute price difference and percentage price difference. Although they have some flaws, they provide an understandable way to assess whether the model meets the business goals. Additionally, estimates based on a combination of absolute difference and percentage difference can also be used.\\n\\n\\n133. Day 2 - LLM Deployment Pipeline- From Business Problem to Production Solution\\n\\nSummary: Text Content from Week 6, Day 2\\n\\nSession Purpose\\n\\nThis session discusses strategies for applying LLMs to solve business problems, optimization techniques for models, & the typical steps involved in implementing an LLM solution. \\n\\nStrategy for LM Solution\\n\\nThe strategy vertically moves from identifying a business problem to deploying an effective model to solve it. Five fundamental steps mark this transition:\\n\\nUnderstanding: Deeply understanding the business requirements and documenting them. Know what problem is being solved, what success looks like, and define non-functional requirements.\\n\\nPreparation: Preparing tasks like testing baseline models, curating data set, and general preparations for succeeding steps.\\n\\n3. Select: Selecting the models beneficial to be used for the project. Decisions are based on previous content examined and analyzed models.\\n\\n4. Customize: Using techniques like Rag or Fine tuning for model optimization.\\n\\n5. Productionize: Following the successful deployment of a trained and functioning model, the next step involves preparing it for production.\\n\\nIn-Depth Look at Steps\\n\\nStep 1: Understanding\\n\\nEvaluate how success is measured and understand business requirements and ultimate business metrics.\\n\\nGather data quantity, quality, and format which influences the model choice and plan.\\n\\nDetermine non-functional requirements like budget, scale, latency issues, time to market, and potential user interface needs.\\n\\nStep 2: Preparation\\n\\nResearch on existing solutions for the problem is a prerequisite.\\n\\nAnalyze non-data science solutions, as well as traditional data science solutions like linear regression.\\n\\nRegardless of the effectiveness of existing models, they provide a baseline for improvement and quantifies the upgrades provided by the newer model.\\n\\nComparing, curating, and dividing data into training, validation, and test sections is paramount.\\n\\nStep 3: Select\\n\\nChoosing the right LLMs based on defined criteria and experimenting with them based on curated data.\\n\\n140. Day 3 - Feature Engineering and Bag of Words- Building ML Baselines for NLP\\n\\nSummary\\n\\nIntroduction\\n\\nWeek six, day three, is dedicated to exploring foundational concepts of traditional machine learning to serve as a baseline before diving back into advanced language models.\\n\\nWhat Has Been Done\\n\\nThe course so far has covered work with frontier models, constructing AI assistants using tools and open-source models such as Hugging Face, with pipelines, tokenizers, and other models.\\n\\nWork with LongChain was discussed for building a complete RAG pipeline.\\n\\nA five-step strategy to tackle commercial problems was outlined.\\n\\nExtensive work with data was done, including charts, item classes, and item loaders.\\n\\nBaselines\\n\\nThe importance of a baseline model is discussed. It serves as the yardstick against which we measure the progress of more sophisticated models.\\n\\nBaselines are also important in cases where language models are not the ideal solution.\\n\\nThe goal is to create a baseline model to predict the prices of products.\\n\\nModels For The Day\\n\\nThe first step would be feature engineering, calculating essential factors likely to affect price.\\n\\nThen, a 'Bag of Words' model will be implemented, a simplistic approach which counts the occurrence of each word in a description.\\n\\nNext, a 'Word2Vec' model, a smarter version of 'Bag of Words', is used, followed by linear regression and Random Forests.\\n\\nFinally, Support Vector Regression, a technique designed for data grouping, will be used.\\n\\nThe efficiency of these different techniques in predicting a product's price from its description will be compared.\\n\\nMastering Traditional Machine Learning\\n\\nEven though traditional machine learning might seem less appealing than advanced language models, understanding it thoroughly is crucial.\\n\\nThe main goal for this day is to build a good understanding and appreciation of these traditional models, as that will lay the base for more sophisticated machine learning concepts.\\n\\n141. Day 3 - Baseline Models in ML- Implementing Simple Prediction Functions\\n\\nSummary\\n\\nJupyterLab Introduction \\n\\nThis content introduces JupyterLab and focuses on baseline models starting with several imports required for machine learning tasks, data organization, and natural language processing tasks. \\n\\nNatural Language Processing \\n\\nThe text also highlights another set of imports related to natural language processing (NLP), including `Gensim`. This library is useful in tasks like word2vec which turns words into vectors, a powerful tool for NLP tasks.\\n\\nTest Harness Creation \\n\\nA chunk of code is presented that allows the testing of different models in a quick, simple way. It involves creating a class `tester` that tests a function (model prediction) against different test data points and visualizes the results.\\n\\nSimple Prediction Models \\n\\nTwo simple prediction models are suggested: \\n\\nRandom Predictor: This model simply returns a random number as the guess for the value of an item. This model acts as a baseline to compare more complex models against.\\n\\nAverage Predictor: This model guesses that every item is priced at the average price of the training dataset.\\n\\nBoth models are demonstrated and evaluated using the `tester` class. \\n\\nThese simplified models are precursors to the machine learning models to be introduced in subsequent lessons.\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f3/8gs03snx5mgb4bxn_w3fxrqw0000gp/T/ipykernel_45436/158126.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 95 documents\n"
     ]
    }
   ],
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "# Chroma is a popular open source Vector Database based on SQLLite\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# If you would rather use the free Vector Embeddings from HuggingFace sentence-transformers\n",
    "# Then replace embeddings = OpenAIEmbeddings()\n",
    "# with:\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Delete if already exists\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create vectorstore\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vectors have 384 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Get one vector and find how many dimensions it has\n",
    "\n",
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Vector Store\n",
    "\n",
    "Let's take a minute to look at the documents and their embedding vectors to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prework\n",
    "\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "doc_types = [metadata['doc_name'] for metadata in result['metadatas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "opacity": 0.8,
          "size": 5
         },
         "mode": "markers",
         "text": [
          "Type: all_summaries copy.docx<br>Text: 128. Day 1 - Fine-Tuning Large Language Models- From Inference to Training\n\nSummary\n\nIntroduction\n\nT...",
          "Type: all_summaries copy.docx<br>Text: Week 3: Explored Hugging Face, Pipelines Tokenizers, and models.\n\nWeek 4: Focused on selecting model...",
          "Type: all_summaries copy.docx<br>Text: Introduction to a New Problem\n\nNext, a commercial problem relating to an e-commerce company is intro...",
          "Type: all_summaries copy.docx<br>Text: 132. Day 1 - Evaluating LLM Performance- Model-Centric vs Business-Centric Metrics\n\nSummary \n\nData S...",
          "Type: all_summaries copy.docx<br>Text: Model Evaluation Metrics\n\nNext, the author delves into how model performance will be assessed — both...",
          "Type: all_summaries copy.docx<br>Text: Business-Centric Metrics\n\nThe speaker then discusses business-centric metrics, including average abs...",
          "Type: all_summaries copy.docx<br>Text: Strategy for LM Solution\n\nThe strategy vertically moves from identifying a business problem to deplo...",
          "Type: all_summaries copy.docx<br>Text: 5. Productionize: Following the successful deployment of a trained and functioning model, the next s...",
          "Type: all_summaries copy.docx<br>Text: Comparing, curating, and dividing data into training, validation, and test sections is paramount.\n\nS...",
          "Type: all_summaries copy.docx<br>Text: A five-step strategy to tackle commercial problems was outlined.\n\nExtensive work with data was done,...",
          "Type: all_summaries copy.docx<br>Text: Finally, Support Vector Regression, a technique designed for data grouping, will be used.\n\nThe effic...",
          "Type: all_summaries copy.docx<br>Text: Natural Language Processing \n\nThe text also highlights another set of imports related to natural lan...",
          "Type: all_summaries copy.docx<br>Text: Average Predictor: This model guesses that every item is priced at the average price of the training...",
          "Type: all_summaries.docx<br>Text: 128. Day 1 - Fine-Tuning Large Language Models- From Inference to Training\n\nSummary\n\nIntroduction\n\nT...",
          "Type: all_summaries.docx<br>Text: Week 3: Explored Hugging Face, Pipelines Tokenizers, and models.\n\nWeek 4: Focused on selecting model...",
          "Type: all_summaries.docx<br>Text: Introduction to a New Problem\n\nNext, a commercial problem relating to an e-commerce company is intro...",
          "Type: all_summaries.docx<br>Text: 132. Day 1 - Evaluating LLM Performance- Model-Centric vs Business-Centric Metrics\n\nSummary \n\nData S...",
          "Type: all_summaries.docx<br>Text: Model Evaluation Metrics\n\nNext, the author delves into how model performance will be assessed — both...",
          "Type: all_summaries.docx<br>Text: Business-Centric Metrics\n\nThe speaker then discusses business-centric metrics, including average abs...",
          "Type: all_summaries.docx<br>Text: Strategy for LM Solution\n\nThe strategy vertically moves from identifying a business problem to deplo...",
          "Type: all_summaries.docx<br>Text: 5. Productionize: Following the successful deployment of a trained and functioning model, the next s...",
          "Type: all_summaries.docx<br>Text: Comparing, curating, and dividing data into training, validation, and test sections is paramount.\n\nS...",
          "Type: all_summaries.docx<br>Text: A five-step strategy to tackle commercial problems was outlined.\n\nExtensive work with data was done,...",
          "Type: all_summaries.docx<br>Text: Finally, Support Vector Regression, a technique designed for data grouping, will be used.\n\nThe effic...",
          "Type: all_summaries.docx<br>Text: Natural Language Processing \n\nThe text also highlights another set of imports related to natural lan...",
          "Type: all_summaries.docx<br>Text: Average Predictor: This model guesses that every item is priced at the average price of the training...",
          "Type: all_summaries.docx<br>Text: Absolute Size of Llama 3.1 and its Implications\n\nThe author notes that even the 8 billion model is p...",
          "Type: all_summaries.docx<br>Text: Laura (Low Rank Adaptation)\n\nThe cornerstone of Laura is freezing the immense amount of weights to p...",
          "Type: all_summaries.docx<br>Text: The upcoming section will share more about 'quantization', another aspect to optimize the model.\n\n\n1...",
          "Type: all_summaries.docx<br>Text: Benefits of Quantization\n\nQuantization, a surprising yet effective method, works to maintain the sam...",
          "Type: all_summaries.docx<br>Text: Secondly, the process of lowering the precision is only applied to the base model. The Lora adapters...",
          "Type: all_summaries.docx<br>Text: Essential Hyperparameters\n\nThe three critical hyperparameters in Q Laura fine tuning involve:\n\nRank ...",
          "Type: all_summaries.docx<br>Text: Following an overview, we apply these hyperparameters in a practical session using Google Colab to b...",
          "Type: all_summaries.docx<br>Text: A Peft model from pre-trained is utilized. It is loaded using the base model as a reference, with th...",
          "Type: all_summaries.docx<br>Text: Parameter Calculation\n\nThe number of weights (parameters) across these adapters is calculated by mul...",
          "Type: all_summaries.docx<br>Text: The discussion concludes with a return to presentation slides for final thoughts.\n\n\nWeek 7\n\n169. Day...",
          "Type: all_summaries.docx<br>Text: original pre-trained version (foundation model)\n\nfine-tuned for chat purposes (instruct variant), wh...",
          "Type: all_summaries.docx<br>Text: Personal Insights\n\nIn my experiment, the base model slightly performed better than the instruct vari...",
          "Type: all_summaries.docx<br>Text: 2.52.5 Variant, the highest scorer.\n\nGemma, a 9 billion parameter model.\n\nMistral\n\nPhi2 from Microso...",
          "Type: all_summaries.docx<br>Text: Phi3, Gemma, and Meta Llama 3.1: These also perform well with 'instruct variants', providing a reali...",
          "Type: all_summaries.docx<br>Text: This selection process is a balance of investigating the leaderboard, learning about instruct varian...",
          "Type: all_summaries.docx<br>Text: 1. Target Modules\n\nThis is a subset of layers within the large architecture of a Transformer model s...",
          "Type: all_summaries.docx<br>Text: 3. Alpha\n\nAlpha is a scaling factor used in weight adjustment, where weight change equals α times tw...",
          "Type: all_summaries.docx<br>Text: 176. Day 3 - Understanding Epochs and Batch Sizes in Model Training\n\nSummary of Hyperparameters in M...",
          "Type: all_summaries.docx<br>Text: Enhanced performance by allowing faster data processing.\n\nDifferent variation of batches with each e...",
          "Type: all_summaries.docx<br>Text: Learning Rate\n\nLearning rate is a critical hyperparameter in training machine learning models.\n\nIt d...",
          "Type: all_summaries.docx<br>Text: It increases efficiency by reducing the frequency of weight adjustments, working in principle somewh...",
          "Type: all_summaries.docx<br>Text: 187. Day 5 - The Four Steps in LLM Training- From Forward Pass to Optimization\n\nIntroduction and Bac...",
          "Type: all_summaries.docx<br>Text: 2. __Loss Calculation:__ This step evaluates the disparity between the network's prediction of the n...",
          "Type: all_summaries.docx<br>Text: An essential clarification is made that this training process always occurs with mini-batches and it...",
          "Type: all_summaries.docx<br>Text: 189. Day 5 - Understanding Softmax and Cross-Entropy Loss in Model Training\n\nUnderstanding the Model...",
          "Type: all_summaries.docx<br>Text: While these strategies bring in a variety, they are not always necessary; picking the token with the...",
          "Type: all_summaries.docx<br>Text: Classification is especially useful for projects involving a wide range of possibilities or buckets ...",
          "Type: all_summaries.docx<br>Text: The content talks about a project primarily focused on providing an understanding of Agentic AI and ...",
          "Type: all_summaries.docx<br>Text: 5. Autonomy - This signifies that the AI system has an existence that transcends a conversation with...",
          "Type: all_summaries.docx<br>Text: A Scanner Agent, worked on previously, collects feeds, calls the GPT4 model for descriptions and pri...",
          "Type: all_summaries.docx<br>Text: I mean, to give you something that comes to mind right away is that when I was looking on hugging fa...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: 142. AI Agents learning path\n\nAgentic AI Learning Path\n\nOverview\n\nThis document discusses the learni...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: Agentic Frameworks\n\nCreation of Simple AI Agents\n\nAI Agents with Memory\n\nCreation of Multi-Agents\n\n1...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: What are AI Agents?\n\nAI agents are smart programs capable of interacting with software, data, and ha...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: Reasoning: AI agents employ techniques such as the chain of thoughts for task analysis and planning ...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: Execution and Iteration: Once they have a plan, AI agents implement it and observe the outcomes. The...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: Summary: Overview of Popular AI Agent Frameworks \n\nThis lecture introduced four popular AI agent fra...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: CrewAI \n\nWith this unnamed AI Automation platform, users can build and deploy automated workflows us...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: The Need for LangGraphs \n\nLang Graph was introduced to handle tasks that call for more intricate wor...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: LangGraph: specific order or in parallel, and those tasks involve complex dependencies, LangGraph’s ...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: Edges\n\nEdges, which connect nodes, come in two types:\n\nConditional Edge: Allows access to any node b...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: The complexity of AI agents can vary, with some defined as a tool using AI for simple function calli...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: AI agents can be built using a variety of platforms, such as the following:\n\nBot Press: A company th...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: LangGraph: A framework built on top of Lang Chain, on which Flow Wise is built.\n\nLang's myth: Primar...",
          "Type: all_summaries_GAI_to_AIAgent_Masterclass_4SoftwareEngineers.docx<br>Text: Kh: llm as operating systems since you can do anything with it specially function calling! function ...",
          "Type: 140. Day 3 - Feature Engineering and Bag of Words- Building ML Baselines for NLP.docx<br>Text: Summary\n\nIntroduction \n\nStarting off with training session 6.3, the focus of today is on foundationa...",
          "Type: 140. Day 3 - Feature Engineering and Bag of Words- Building ML Baselines for NLP.docx<br>Text: The Business Problem \n\nIn the specific context of predicting product prices, the question of which m...",
          "Type: 140. Day 3 - Feature Engineering and Bag of Words- Building ML Baselines for NLP.docx<br>Text: 4. **Random forests** - This method combines multiple models and averages across many data and featu...",
          "Type: 141. Day 3 - Baseline Models in ML- Implementing Simple Prediction Functions.docx<br>Text: Summary\n\nThe content provides an in-depth exploration and application of baseline models in the cont...",
          "Type: 141. Day 3 - Baseline Models in ML- Implementing Simple Prediction Functions.docx<br>Text: The author demonstrates the use of the platform, explaining how to run cells, how to load data (e.g....",
          "Type: 141. Day 3 - Baseline Models in ML- Implementing Simple Prediction Functions.docx<br>Text: The guide served as a precursor to examining real machine learning models in the upcoming sessions. ...",
          "Type: AISera_2024.pdf<br>Text: LLM Evaluation: Key Metrics and Best\nPractices\nArtificial intelligence technology has yielded\nexcept...",
          "Type: AISera_2024.pdf<br>Text: Introduction to LLM Evaluation\nWhat is LLM Evaluation?\nLLM Evaluation Metrics\nEvaluation Templates\nA...",
          "Type: AISera_2024.pdf<br>Text: Overview of LLMs\nIn the current landscape, the application of large language models is significantly...",
          "Type: AISera_2024.pdf<br>Text: Primarily, it provides a window into the model’s reliability and efficiency—key factors\ndetermining ...",
          "Type: AISera_2024.pdf<br>Text: When deploying LLMs in education, for instance, developers meticulously examine the age-\nappropriate...",
          "Type: AISera_2024.pdf<br>Text: applications community feedback\nMinimization of\nToxicity\nVital for all public-facing\napplications\nTo...",
          "Type: AISera_2024.pdf<br>Text: Evaluation Templates\nYou can choose a variety of prompt templates for evaluating your fine-tuned lar...",
          "Type: AISera_2024.pdf<br>Text: Performance Assessment\nIn assessing the performance of LLMs, a range of metrics are utilized to unde...",
          "Type: AISera_2024.pdf<br>Text: Performance\nIndicator Metric Application in LLM Evaluation\nAccuracy Task Success\nRate\nMeasuring the ...",
          "Type: AISera_2024.pdf<br>Text: LLM Model Evals Versus LLM System Evals\nUnderstanding the nuances between LLM evaluations and LLM sy...",
          "Type: AISera_2024.pdf<br>Text: improving LLM evaluation methods.\nFoundational model builders consistently push the frontiers of wha...",
          "Type: AISera_2024.pdf<br>Text: Upon completing these steps, you’ll have a thorough understanding of how LLMs perform\nunder a variet...",
          "Type: AISera_2024.pdf<br>Text: Multiple LLM evaluation metrics\nIn the pursuit of LLM evaluation best practices, deploying a diversi...",
          "Type: AISera_2024.pdf<br>Text: Gain exceptional user experience & reduce support cost.\nFor those eager to witness the transformativ...",
          "Type: AISera_2024.pdf<br>Text: Custom Gen AI Demo\nProducts\nAiseraGPT\nAI Copilot\nAI Search\nAgent Assist\nAI Voice Bot\nGen AI Platform...",
          "Type: AISera_2024.pdf<br>Text: Platform\nConversational AI\nAI Workflows\nAI Customer Intelligence\nAI Support Intelligence\nAI SQL Dial...",
          "Type: AISera_2024.pdf<br>Text: Company\nPartners\nAisera Gen AI Academy\nNews Coverage\nPress Releases\nCareers\nContact Us\nTrust\nTRAPS F...",
          "Type: AISera_2024.pdf<br>Text: Let’s Work Together\nGet answers and a customized\nquote for your projects\nSubmit RFP\nSitemap | 2024 A..."
         ],
         "type": "scatter",
         "x": {
          "bdata": "x6SDQQpYDkJ0SNHCoN+KwjsYq8I9HcXCnXfbQfXO7UDrOxLB/UzLwvs8ncJOtDfCKVF9wsekg0EKWA5CVsu7whKFhcKY8b/C6BjYwp1320ENuXZB6zsSwf1My8L7PJ3CTrQ3wpwP40JpctlCpujSQgIh4UK1nfFC4JO/QuQbmELj35xCBDSzQvKb+EI7hQdCoBbhQd2WO0KvKNdCD0fBQqdGd0JiFZ5C70KvQky9OELAm3NCZZCGQtS2d0KqmjFCGkkoQqUw9ELlnWfC1kiIws0eKMFCpMlAO94JwefIxMFMuvXCHL+EQI7WnkCW8qs/huRuQWZCokGKGvpBxqs/QjRfiELTT35Cx2MUQvcIwUGyLydCZOMdQqgWJ0ErcrLAjzfBwqmDpsIPfYDCGd4xwhYz18G+O4PBooC5wTlCyUBfzLnB6UpHwtb+OsGINgLCI0QcwvPR9sEBHh/BCEtwv8vMk8FO+P7AGyEfwubWLcL7HO/BThxOwv4TE8I=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "IGrHQMApkMCnSBq/3GEYwtfOh8JV/hnC/7a8wsDX1cLbKW5BZA0SQiLD20GNYMJBHKo6QiBqx0DAKZDAvbDBvz9kQcIpP4vCT2ktwv+2vMKlpeTC2yluQWQNEkIiw9tBjWDCQafYwsHBohPCyvQTwKtXX0GHo8JBgJfYQPVCl0BydqHBdRiOwTHAH8HdtadBKvkDQkPu50FLE2zCqJliwqWi8MBJtpNBnQX7QeauY8JQnWvCHddDwmz1AMLYZsbBUQ4ZwhTjJsJ6JapCPZKwQry2qkKI39lCbtfNQu1/10JNAx5BcbGYQlUbuUJ26fdCkr74QpEfsUL+8pdCR6GfQtQFnUKEU7RCo0X2Qlqh1UKqf9NCMYS5QvJ0a8ILXgZCYsijQX7CNkLSlTZBCxg1QrPjJUJ86GvCwBT8we9BBcKAIjvCKhKVwclgm8IvU5DBQdsBwsoehcKtVuTBE/t4wZ1YaMHfuSrCu7RSwjkCo8JvrafCZl+7wujMxsI=",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "height": 600,
        "margin": {
         "b": 10,
         "l": 10,
         "r": 20,
         "t": 40
        },
        "scene": {
         "xaxis": {
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "title": {
           "text": "y"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "2D Chroma Vector Store Visualization"
        },
        "width": 800
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We humans find it easier to visalize things in 2D!\n",
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
